{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# filter warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "# keras imports\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.models import model_from_json\n",
    "# keras uses tensor flow backend\n",
    "\n",
    "# other imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import h5py\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mGBBR Anatomy of The Ring Completed 7-28-2017.xlsx\u001b[m\u001b[m*\r\n",
      "\u001b[1m\u001b[36mPics\u001b[m\u001b[m/\r\n",
      "TransferTraining.ipynb\r\n",
      "config.json\r\n",
      "\u001b[31meshop_items_full.csv\u001b[m\u001b[m*\r\n",
      "gab_nn.ipynb\r\n",
      "neighbors_model_1.json\r\n",
      "test.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the user configs\n",
    "with open('config.json') as f:    \n",
    "    config = json.load(f)\n",
    "\n",
    "# config variables\n",
    "model_name = config[\"model\"]\n",
    "weights = config[\"weights\"]\n",
    "include_top = config[\"include_top\"]\n",
    "train_path = config[\"train_path\"]\n",
    "features_path = config[\"features_path\"]\n",
    "labels_path = config[\"labels_path\"]\n",
    "test_size = config[\"test_size\"]\n",
    "results = config[\"results\"]\n",
    "model_path = config[\"model_path\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xception'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] start time - 2017-08-15 11:56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryan_skorupski/anaconda2/envs/integris3/lib/python3.5/site-packages/ipykernel/__main__.py:27: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"av..., inputs=Tensor(\"in...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] successfully loaded base model and model...\n",
      "0\n",
      "done\n",
      "1000\n",
      "done\n",
      "2000\n",
      "done\n",
      "3000\n",
      "done\n",
      "4000\n",
      "done\n",
      "5000\n",
      "done\n",
      "6000\n",
      "done\n",
      "7000\n",
      "done\n",
      "8000\n",
      "done\n",
      "9000\n",
      "done\n",
      "10000\n",
      "done\n",
      "11000\n",
      "done\n",
      "12000\n",
      "done\n",
      "13000\n",
      "done\n",
      "14000\n",
      "done\n",
      "15000\n",
      "done\n",
      "16000\n",
      "done\n",
      "17000\n",
      "done\n",
      "18000\n",
      "done\n",
      "19000\n",
      "done\n",
      "20000\n",
      "done\n",
      "21000\n",
      "done\n",
      "22000\n",
      "done\n",
      "23000\n",
      "done\n",
      "24000\n",
      "done\n",
      "25000\n",
      "done\n",
      "26000\n",
      "done\n",
      "27000\n",
      "done\n",
      "28000\n",
      "done\n",
      "29000\n",
      "done\n",
      "30000\n",
      "done\n",
      "31000\n",
      "done\n",
      "32000\n",
      "done\n",
      "33000\n",
      "done\n",
      "34000\n",
      "done\n",
      "35000\n",
      "done\n",
      "36000\n",
      "done\n",
      "37000\n",
      "done\n",
      "38000\n",
      "done\n",
      "39000\n",
      "done\n",
      "40000\n",
      "done\n",
      "41000\n",
      "done\n",
      "42000\n",
      "done\n",
      "43000\n",
      "done\n",
      "44000\n",
      "done\n",
      "45000\n",
      "done\n",
      "46000\n",
      "done\n",
      "47000\n",
      "done\n",
      "48000\n",
      "done\n",
      "49000\n",
      "done\n",
      "50000\n",
      "done\n",
      "51000\n",
      "done\n",
      "52000\n",
      "done\n",
      "53000\n",
      "done\n",
      "54000\n",
      "done\n",
      "[STATUS] end time - 2017-08-17 16:21\n"
     ]
    }
   ],
   "source": [
    "# start time\n",
    "print(\"[STATUS] start time - {}\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")))\n",
    "start = time.time()\n",
    "\n",
    "# create the pretrained models\n",
    "# check for pretrained weight usage or not\n",
    "# check for top layers to be included or not\n",
    "if model_name == \"vgg16\":\n",
    "    base_model = VGG16(weights=weights)\n",
    "    model = Model(input=base_model.input, output=base_model.get_layer('fc1').output)\n",
    "    image_size = (224, 224)\n",
    "elif model_name == \"vgg19\":\n",
    "    base_model = VGG19(weights=weights)\n",
    "    model = Model(input=base_model.input, output=base_model.get_layer('fc1').output)\n",
    "    image_size = (224, 224)\n",
    "elif model_name == \"resnet50\":\n",
    "    base_model = ResNet50(weights=weights)\n",
    "    model = Model(input=base_model.input, output=base_model.get_layer('flatten').output)\n",
    "    image_size = (224, 224)\n",
    "elif model_name == \"inceptionv3\":\n",
    "    model = InceptionV3(weights=weights, include_top=False)\n",
    "    #base_model = InceptionV3(weights=weights)\n",
    "    #model = Model(input=base_model.input, output=base_model.get_layer('flatten').output)\n",
    "    image_size = (299, 299)\n",
    "elif model_name == \"xception\":\n",
    "    base_model = Xception(weights=weights)\n",
    "    model = Model(input=base_model.input, output=base_model.get_layer('avg_pool').output)\n",
    "    image_size = (299, 299)\n",
    "else:\n",
    "    base_model = None\n",
    "\n",
    "print(\"[INFO] successfully loaded base model and model...\")\n",
    "\n",
    "# path to training dataset\n",
    "train_labels = os.listdir(train_path)\n",
    "train_labels = train_labels\n",
    "\n",
    "# encode the labels\n",
    "# print(\"[INFO] encoding labels...\")\n",
    "# le = LabelEncoder()\n",
    "# le.fit([tl for tl in train_labels])\n",
    "\n",
    "# empty pandas frame\n",
    "extracted_cols = ['name', 'feature']\n",
    "extracted_df = pd.DataFrame(columns=extracted_cols)  # create empty frame\n",
    "\n",
    "# variables to hold features and labels\n",
    "features = []\n",
    "labels   = []\n",
    "\n",
    "\n",
    "# loop over all the labels in the folder\n",
    "# for i, label in enumerate(train_labels):\n",
    "# cur_path = train_path + \"/\" + train_labels\n",
    "for idx, image_path in enumerate(train_labels): # glob.glob(cur_path + \"/*.jpg\"):\n",
    "    img = image.load_img(train_path + \"/\" + image_path, target_size=image_size)\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    feature = model.predict(x)\n",
    "#     print(feature)\n",
    "#     print(len(feature))\n",
    "    flat = feature.flatten()\n",
    "    \n",
    "    extracted_df.loc[idx] = [image_path, flat]\n",
    "    \n",
    "    if idx%1000 == 0:\n",
    "        print(idx)\n",
    "        print('done')\n",
    "        current_dir = os.getcwd()\n",
    "        filename = current_dir + '/' + results\n",
    "        extracted_df.to_pickle(filename)\n",
    "\n",
    "#     features.append(flat)\n",
    "#     labels.append(label)\n",
    "#   print(\"[INFO] processed - {}\".format(image_path))\n",
    "#print(\"[INFO] completed feature extraction\")\n",
    "\n",
    "# encode the labels using LabelEncoder\n",
    "# targetNames = np.unique(labels)\n",
    "# le = LabelEncoder()\n",
    "# le_labels = le.fit_transform(labels)\n",
    "\n",
    "# get the shape of training labels\n",
    "# print \"[STATUS] training labels: {}\".format(le_labels)\n",
    "# print \"[STATUS] training labels shape: {}\".format(le_labels.shape)\n",
    "\n",
    "# save features and labels\n",
    "#h5f_data = h5py.File(features_path, 'w')\n",
    "#h5f_data.create_dataset('dataset_1', data=np.array(features))\n",
    "\n",
    "#h5f_label = h5py.File(labels_path, 'w')\n",
    "#h5f_label.create_dataset('dataset_1', data=np.array(le_labels))\n",
    "\n",
    "#h5f_data.close()\n",
    "#h5f_label.close()\n",
    "\n",
    "# save model and weights\n",
    "# model_json = model.to_json()\n",
    "# with open(model_path + str(test_size) + \".json\", \"w\") as json_file:\n",
    "#     json_file.write(model_json)\n",
    "\n",
    "# save weights\n",
    "# model.save_weights(model_path + str(test_size) + \".h5\")\n",
    "# print(\"[STATUS] saved model and weights to disk..\")\n",
    "\n",
    "# print \"[STATUS] features and labels saved..\"\n",
    "\n",
    "# save df to csv\n",
    "current_dir = os.getcwd()\n",
    "filename = current_dir + '/' + results\n",
    "extracted_df.to_pickle(filename)\n",
    "# extracted_df.to_csv(filename,  index = False)\n",
    "\n",
    "\n",
    "# end time\n",
    "end = time.time()\n",
    "print(\"[STATUS] end time - {}\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54778"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(extracted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(extracted_df['feature'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_pickle(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71897906"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['feature'][0][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
